{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\ML\\RAG\\.venv\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "import PyPDF2\n",
    "import torch\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sentence_transformers import SentenceTransformer, SimilarityFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_file = \"./documents/epix_(Gen_2)_Series_OM_EN-US.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\ML\\RAG\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Set similarity functdion\n",
    "similarity_fn_name = SimilarityFunction.COSINE\n",
    "#similarity_fn_name = SimilarityFunction.DOT_PRODUCT\n",
    "#similarity_fn_name = SimilarityFunction.EUCLIDEAN\n",
    "\n",
    "# Initialize encoding model\n",
    "model = SentenceTransformer(\"all-mpnet-base-v2\", similarity_fn_name=similarity_fn_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract text from PDF\n",
    "def extract_text(pdf_path):\n",
    "\n",
    "\textracted_text = []\n",
    "\n",
    "\twith open(pdf_path, \"rb\") as pdf_file:\n",
    "\n",
    "\t\t# Instantiate PyPDF reader\n",
    "\t\treader = PyPDF2.PdfReader(pdf_file)\n",
    "\n",
    "\t\t# Parse each page\n",
    "\t\tfor page in reader.pages:\n",
    "\n",
    "\t\t\t# Extract page text\n",
    "\t\t\tpage_text = page.extract_text().encode(\"utf-8\", \"xmlcharrefreplace\")\n",
    "\t\t\tpage_text = page_text.decode(\"utf-8\")\n",
    "\n",
    "\t\t\t# Replace known characters\n",
    "\t\t\tpage_text = page_text.replace(\"\\n\", \" \")\n",
    "\t\t\tpage_text = page_text.replace(\"\\xa0\", \"\")\n",
    "\t\t\tpage_text = page_text.replace(\"\\xad \", \"\")\n",
    "\n",
    "\t\t\t# Split the page text into sentences\n",
    "\t\t\tsentences = sent_tokenize(page_text)\n",
    "\t\t\textracted_text.extend(sentences)\n",
    "\n",
    "\treturn extracted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 3899\n"
     ]
    }
   ],
   "source": [
    "# Extract text from PDF file\n",
    "extracted_text = extract_text(pdf_file)\n",
    "print(f\"Number of sentences: {len(extracted_text)}\")\n",
    "#print(extracted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(sentences, model):\n",
    "\n",
    "\t# Generate sentence embeddings\n",
    "\tsentence_embeddings = model.encode(sentences)\n",
    "\n",
    "\treturn sentences, sentence_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3899, 768)\n"
     ]
    }
   ],
   "source": [
    "# Vectorize text\n",
    "sentences, sentence_embeddings = vectorize_text(extracted_text, model)\n",
    "\n",
    "print(sentence_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate RAG response\n",
    "def generate_response(query_text, context):\n",
    "\n",
    "\t# Pass query and context to LLM\n",
    "\tsystem_message = f\"\"\"\n",
    "\t\tYou are a knowledgeable assistant tasked with answering questions based solely on the provided context.\n",
    "\t\tYour responses should be strictly based on the information contained in the context.\n",
    "\t\tIf the answer is not clear from the context, you can extrapolate from the information available in the context.\n",
    "\t\tIf the answer is not in the context, respond with \"The answer is not available in the provided context.\"\n",
    "\t\tHere is the context you should use:\n",
    "\t\t{context}\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t# Generate response\n",
    "\tresponse = ollama.chat(model=\"llama3.1\", messages=[\n",
    "\t\t{\n",
    "\t\t\t\"role\": \"system\",\n",
    "\t\t\t\"content\": system_message\n",
    "\t\t},\n",
    "\t\t{\n",
    "\t\t\t\"role\": \"user\",\n",
    "\t\t\t\"content\": f\"{query_text}\"\n",
    "\t\t}\n",
    "\t])\n",
    "\n",
    "\treturn response[\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the knowledge base\n",
    "def query_kb(query_text, sentence_embeddings, model, show_context=False):\n",
    "\n",
    "\t# Generate embeddings for the query text\n",
    "\tquery_embeddings = model.encode(query_text)\n",
    "\n",
    "\t# Generate tensor of similarities between query and sentences\n",
    "\tsimilarities = model.similarity(query_embeddings, sentence_embeddings)\n",
    "\t\n",
    "\t# Extract top k similar sentences\n",
    "\tk = 25\n",
    "\ttop_k_indices = torch.topk(similarities, k).indices.tolist()\n",
    "\ttop_k_indices = [item for sublist in top_k_indices for item in sublist]\n",
    "\trelevant_sentences = [sentences[i] for i in top_k_indices]\n",
    "\n",
    "\t# Generate LLM response using similar sentences as context\n",
    "\tresponse = generate_response(query_text, relevant_sentences)\n",
    "\n",
    "\t# DEBUG\n",
    "\tif show_context:\n",
    "\t\tprint(\"#### CONTEXT ####\")\n",
    "\t\tprint(\"\\n\".join(relevant_sentences))\n",
    "\t\tprint(\"####################\\n\")\n",
    "\n",
    "\treturn response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epix Questions\n",
    "\n",
    "#query_text = \"How deep can I swim while wearing the watch?\"\n",
    "#query_text = \"How much water pressure can the watch withstand?\"\n",
    "#query_text = \"How do I navigate back home when I'm on a run?\"\n",
    "#query_text = \"How do I get a SpO2 measurement?\"\n",
    "query_text = \"How do I set an alarm?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To set an alarm, follow these steps: \n",
      "\n",
      "1. Select Clocks.\n",
      "2. Select ALARMS.\n",
      "3. Select Add Alarm.\n",
      "\n",
      "You can also select Clocks > ALARMS to view and manage existing alarms.\n",
      "\n",
      "Additionally, you can set multiple alarms by selecting Clocks and then following the on-screen instructions to add each individual alarm.\n"
     ]
    }
   ],
   "source": [
    "response = query_kb(query_text, sentence_embeddings, model, show_context=False)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
